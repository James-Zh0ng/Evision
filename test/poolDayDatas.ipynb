{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640-19669\n",
      "Data for pool USDC-ETH processed and saved to data/poolDayData_0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0x99ac8ca7087fa4a2a1fb6357269965a2014abc35-19669\n",
      "Data for pool WBTC-USDC processed and saved to data/poolDayData_0x99ac8cA7087fA4A2A1FB6357269965A2014ABc35.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0xd0fc8ba7e267f2bc56044a7715a489d851dc6d78-19669\n",
      "Data for pool UNI-USDC processed and saved to data/poolDayData_0xD0fC8bA7E267f2bc56044A7715A489d851dC6D78.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0x78235d08b2ae7a3e00184329212a4d7acd2f9985-19669\n",
      "Inserting data at 2022-06-14\n",
      "Inserting data at 2022-06-15\n",
      "Inserting data at 2022-06-16\n",
      "Inserting data at 2022-06-18\n",
      "Inserting data at 2022-06-19\n",
      "Inserting data at 2022-06-20\n",
      "Inserting data at 2022-06-21\n",
      "Inserting data at 2022-06-22\n",
      "Inserting data at 2022-06-23\n",
      "Inserting data at 2022-06-24\n",
      "Inserting data at 2022-06-25\n",
      "Inserting data at 2022-06-26\n",
      "Inserting data at 2022-06-27\n",
      "Inserting data at 2022-06-28\n",
      "Inserting data at 2022-06-29\n",
      "Inserting data at 2022-06-30\n",
      "Inserting data at 2022-07-01\n",
      "Inserting data at 2022-07-02\n",
      "Inserting data at 2022-07-03\n",
      "Inserting data at 2022-07-04\n",
      "Inserting data at 2022-07-05\n",
      "Inserting data at 2022-07-06\n",
      "Inserting data at 2022-07-07\n",
      "Inserting data at 2022-07-13\n",
      "Inserting data at 2022-07-14\n",
      "Inserting data at 2022-07-15\n",
      "Inserting data at 2022-07-16\n",
      "Inserting data at 2022-07-17\n",
      "Inserting data at 2022-07-18\n",
      "Inserting data at 2022-07-19\n",
      "Inserting data at 2022-07-20\n",
      "Inserting data at 2022-07-21\n",
      "Inserting data at 2022-07-22\n",
      "Inserting data at 2022-07-23\n",
      "Inserting data at 2022-07-24\n",
      "Inserting data at 2022-07-25\n",
      "Inserting data at 2022-07-26\n",
      "Inserting data at 2022-07-27\n",
      "Inserting data at 2022-07-28\n",
      "Inserting data at 2022-07-29\n",
      "Inserting data at 2022-07-30\n",
      "Inserting data at 2022-07-31\n",
      "Inserting data at 2022-08-01\n",
      "Inserting data at 2022-08-02\n",
      "Inserting data at 2022-08-03\n",
      "Inserting data at 2022-08-24\n",
      "Inserting data at 2022-08-28\n",
      "Inserting data at 2022-10-13\n",
      "Inserting data at 2022-10-14\n",
      "Inserting data at 2022-11-10\n",
      "Inserting data at 2023-04-18\n",
      "Inserting data at 2023-04-23\n",
      "Inserting data at 2023-04-24\n",
      "Inserting data at 2023-04-25\n",
      "Inserting data at 2023-04-28\n",
      "Inserting data at 2023-04-29\n",
      "Inserting data at 2023-04-30\n",
      "Inserting data at 2023-05-05\n",
      "Inserting data at 2023-05-07\n",
      "Inserting data at 2023-05-13\n",
      "Inserting data at 2023-05-14\n",
      "Inserting data at 2023-05-16\n",
      "Inserting data at 2023-05-19\n",
      "Inserting data at 2023-05-20\n",
      "Inserting data at 2023-05-22\n",
      "Inserting data at 2023-05-27\n",
      "Inserting data at 2023-05-29\n",
      "Inserting data at 2023-06-01\n",
      "Inserting data at 2023-06-03\n",
      "Inserting data at 2023-06-12\n",
      "Inserting data at 2023-06-19\n",
      "Inserting data at 2023-06-23\n",
      "Inserting data at 2023-06-27\n",
      "Inserting data at 2023-07-02\n",
      "Inserting data at 2023-07-04\n",
      "Inserting data at 2023-07-10\n",
      "Inserting data at 2023-07-12\n",
      "Inserting data at 2023-07-31\n",
      "Inserting data at 2023-08-22\n",
      "Inserting data at 2023-08-28\n",
      "Inserting data at 2023-08-30\n",
      "Inserting data at 2023-09-02\n",
      "Inserting data at 2023-09-03\n",
      "Inserting data at 2023-09-05\n",
      "Inserting data at 2023-09-07\n",
      "Inserting data at 2023-09-09\n",
      "Inserting data at 2023-09-11\n",
      "Inserting data at 2023-09-13\n",
      "Inserting data at 2023-09-14\n",
      "Inserting data at 2023-09-17\n",
      "Inserting data at 2023-09-19\n",
      "Inserting data at 2023-09-23\n",
      "Inserting data at 2023-09-24\n",
      "Inserting data at 2023-09-25\n",
      "Inserting data at 2023-09-26\n",
      "Inserting data at 2023-09-27\n",
      "Inserting data at 2023-10-03\n",
      "Inserting data at 2023-10-04\n",
      "Inserting data at 2023-10-05\n",
      "Inserting data at 2023-10-06\n",
      "Inserting data at 2023-10-07\n",
      "Inserting data at 2023-10-08\n",
      "Inserting data at 2023-10-12\n",
      "Inserting data at 2023-10-13\n",
      "Inserting data at 2023-10-20\n",
      "Data for pool LDO-USDC processed and saved to data/poolDayData_0x78235D08B2aE7a3E00184329212a4d7AcD2F9985.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0xfad57d2039c21811c8f2b5d5b65308aa99d31559-19669\n",
      "Inserting data at 2021-05-10\n",
      "Inserting data at 2021-05-20\n",
      "Inserting data at 2022-05-01\n",
      "Inserting data at 2022-05-02\n",
      "Inserting data at 2022-05-08\n",
      "Inserting data at 2022-05-09\n",
      "Inserting data at 2022-05-10\n",
      "Inserting data at 2022-05-11\n",
      "Inserting data at 2022-05-14\n",
      "Inserting data at 2022-05-16\n",
      "Inserting data at 2022-05-17\n",
      "Inserting data at 2022-05-18\n",
      "Inserting data at 2022-05-19\n",
      "Inserting data at 2022-05-20\n",
      "Inserting data at 2022-05-21\n",
      "Inserting data at 2022-05-23\n",
      "Inserting data at 2022-05-24\n",
      "Inserting data at 2022-05-25\n",
      "Inserting data at 2022-05-26\n",
      "Inserting data at 2022-05-27\n",
      "Inserting data at 2022-05-29\n",
      "Inserting data at 2022-05-30\n",
      "Inserting data at 2022-06-02\n",
      "Inserting data at 2022-06-03\n",
      "Inserting data at 2022-06-04\n",
      "Inserting data at 2022-06-05\n",
      "Inserting data at 2022-06-07\n",
      "Inserting data at 2022-06-10\n",
      "Inserting data at 2022-06-11\n",
      "Inserting data at 2022-06-14\n",
      "Inserting data at 2022-06-16\n",
      "Inserting data at 2022-06-17\n",
      "Inserting data at 2022-06-22\n",
      "Inserting data at 2022-06-26\n",
      "Inserting data at 2022-06-28\n",
      "Inserting data at 2022-06-29\n",
      "Inserting data at 2022-06-30\n",
      "Inserting data at 2022-07-02\n",
      "Inserting data at 2022-07-03\n",
      "Inserting data at 2022-07-04\n",
      "Inserting data at 2022-07-07\n",
      "Inserting data at 2022-07-10\n",
      "Inserting data at 2022-07-11\n",
      "Data for pool LINK-USDC processed and saved to data/poolDayData_0xFAD57d2039C21811C8F2B5D5B65308aa99D31559.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0x07a6e955ba4345bae83ac2a6faa771fddd8a2011-19669\n",
      "Inserting data at 2021-05-21\n",
      "Inserting data at 2021-05-22\n",
      "Inserting data at 2021-05-23\n",
      "Inserting data at 2021-05-24\n",
      "Inserting data at 2021-05-26\n",
      "Inserting data at 2021-05-27\n",
      "Inserting data at 2021-05-28\n",
      "Inserting data at 2021-05-29\n",
      "Inserting data at 2021-05-30\n",
      "Inserting data at 2021-05-31\n",
      "Inserting data at 2021-06-01\n",
      "Inserting data at 2022-05-02\n",
      "Inserting data at 2022-05-10\n",
      "Inserting data at 2022-06-04\n",
      "Inserting data at 2022-06-19\n",
      "Inserting data at 2022-06-20\n",
      "Inserting data at 2022-06-21\n",
      "Inserting data at 2022-06-22\n",
      "Inserting data at 2022-06-23\n",
      "Inserting data at 2022-06-24\n",
      "Inserting data at 2022-06-25\n",
      "Inserting data at 2022-06-26\n",
      "Inserting data at 2022-06-27\n",
      "Inserting data at 2022-06-28\n",
      "Inserting data at 2022-06-29\n",
      "Inserting data at 2022-06-30\n",
      "Inserting data at 2022-07-01\n",
      "Inserting data at 2022-07-02\n",
      "Inserting data at 2022-07-03\n",
      "Inserting data at 2022-07-05\n",
      "Inserting data at 2022-07-06\n",
      "Data for pool MATIC-USDC processed and saved to data/poolDayData_0x07A6E955bA4345BAe83Ac2A6fAa771fddd8A2011.json\n",
      "Fetching pool day data after ID \n",
      "Fetching pool day data after ID 0xb06e7ed37cfa8f0f2888355dd1913e45412798c5-19669\n",
      "Inserting data at 2021-06-02\n",
      "Inserting data at 2021-06-11\n",
      "Inserting data at 2021-10-07\n",
      "Inserting data at 2021-12-11\n",
      "Inserting data at 2021-12-15\n",
      "Inserting data at 2021-12-16\n",
      "Inserting data at 2021-12-17\n",
      "Inserting data at 2022-01-09\n",
      "Inserting data at 2022-01-10\n",
      "Inserting data at 2022-01-11\n",
      "Inserting data at 2022-01-18\n",
      "Inserting data at 2022-01-19\n",
      "Inserting data at 2022-01-21\n",
      "Inserting data at 2022-01-22\n",
      "Inserting data at 2022-01-24\n",
      "Inserting data at 2022-01-25\n",
      "Inserting data at 2022-01-26\n",
      "Inserting data at 2022-01-27\n",
      "Inserting data at 2022-01-28\n",
      "Inserting data at 2022-01-30\n",
      "Inserting data at 2022-02-01\n",
      "Inserting data at 2022-02-02\n",
      "Inserting data at 2022-03-05\n",
      "Inserting data at 2022-04-09\n",
      "Inserting data at 2022-04-18\n",
      "Inserting data at 2022-04-19\n",
      "Inserting data at 2022-05-12\n",
      "Inserting data at 2022-05-13\n",
      "Inserting data at 2022-05-18\n",
      "Inserting data at 2022-05-20\n",
      "Inserting data at 2022-05-21\n",
      "Inserting data at 2022-05-22\n",
      "Inserting data at 2022-05-23\n",
      "Inserting data at 2022-05-24\n",
      "Inserting data at 2022-05-25\n",
      "Inserting data at 2022-05-26\n",
      "Inserting data at 2022-05-27\n",
      "Inserting data at 2022-05-29\n",
      "Inserting data at 2022-05-30\n",
      "Inserting data at 2022-05-31\n",
      "Inserting data at 2022-06-01\n",
      "Inserting data at 2022-06-02\n",
      "Inserting data at 2022-06-03\n",
      "Inserting data at 2022-06-04\n",
      "Inserting data at 2022-06-05\n",
      "Inserting data at 2022-08-12\n",
      "Inserting data at 2022-09-04\n",
      "Inserting data at 2022-09-28\n",
      "Inserting data at 2022-09-30\n",
      "Inserting data at 2022-10-01\n",
      "Inserting data at 2022-10-02\n",
      "Inserting data at 2022-10-09\n",
      "Inserting data at 2022-12-09\n",
      "Inserting data at 2022-12-11\n",
      "Inserting data at 2022-12-12\n",
      "Inserting data at 2022-12-13\n",
      "Inserting data at 2022-12-14\n",
      "Inserting data at 2022-12-15\n",
      "Inserting data at 2022-12-17\n",
      "Inserting data at 2022-12-18\n",
      "Inserting data at 2022-12-19\n",
      "Inserting data at 2022-12-21\n",
      "Inserting data at 2022-12-22\n",
      "Inserting data at 2022-12-24\n",
      "Inserting data at 2022-12-25\n",
      "Inserting data at 2022-12-26\n",
      "Inserting data at 2022-12-27\n",
      "Inserting data at 2022-12-29\n",
      "Inserting data at 2022-12-30\n",
      "Inserting data at 2023-01-01\n",
      "Inserting data at 2023-01-02\n",
      "Inserting data at 2023-01-03\n",
      "Inserting data at 2023-01-05\n",
      "Inserting data at 2023-01-07\n",
      "Inserting data at 2023-01-11\n",
      "Inserting data at 2023-01-13\n",
      "Inserting data at 2023-01-14\n",
      "Inserting data at 2023-01-15\n",
      "Inserting data at 2023-01-16\n",
      "Inserting data at 2023-01-17\n",
      "Inserting data at 2023-01-18\n",
      "Inserting data at 2023-01-19\n",
      "Inserting data at 2023-01-20\n",
      "Inserting data at 2023-01-21\n",
      "Inserting data at 2023-01-22\n",
      "Inserting data at 2023-01-23\n",
      "Inserting data at 2023-01-24\n",
      "Inserting data at 2023-01-25\n",
      "Inserting data at 2023-01-26\n",
      "Inserting data at 2023-01-27\n",
      "Inserting data at 2023-01-28\n",
      "Inserting data at 2023-01-29\n",
      "Inserting data at 2023-01-30\n",
      "Inserting data at 2023-01-31\n",
      "Inserting data at 2023-02-02\n",
      "Inserting data at 2023-02-03\n",
      "Inserting data at 2023-04-08\n",
      "Inserting data at 2023-04-11\n",
      "Inserting data at 2023-04-13\n",
      "Inserting data at 2023-04-22\n",
      "Inserting data at 2023-04-24\n",
      "Inserting data at 2023-04-25\n",
      "Inserting data at 2023-04-29\n",
      "Inserting data at 2023-05-05\n",
      "Inserting data at 2023-05-10\n",
      "Inserting data at 2023-05-11\n",
      "Inserting data at 2023-05-13\n",
      "Inserting data at 2023-05-18\n",
      "Inserting data at 2023-05-20\n",
      "Inserting data at 2023-05-23\n",
      "Inserting data at 2023-05-24\n",
      "Inserting data at 2023-05-26\n",
      "Inserting data at 2023-06-02\n",
      "Inserting data at 2023-06-12\n",
      "Inserting data at 2023-08-26\n",
      "Inserting data at 2023-08-27\n",
      "Inserting data at 2023-09-02\n",
      "Inserting data at 2023-09-08\n",
      "Inserting data at 2023-09-12\n",
      "Inserting data at 2023-09-14\n",
      "Inserting data at 2023-09-20\n",
      "Inserting data at 2023-09-23\n",
      "Inserting data at 2023-09-25\n",
      "Inserting data at 2023-09-29\n",
      "Inserting data at 2023-10-03\n",
      "Inserting data at 2023-10-06\n",
      "Inserting data at 2023-10-08\n",
      "Inserting data at 2023-10-14\n",
      "Inserting data at 2023-10-16\n",
      "Inserting data at 2023-10-24\n",
      "Data for pool USDC-GRT processed and saved to data/poolDayData_0xB06E7Ed37CFA8F0f2888355DD1913e45412798c5.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "UNISWAP_V3_SUBGRAPH_URL = \"https://api.thegraph.com/subgraphs/name/uniswap/uniswap-v3\"\n",
    "\n",
    "# GraphQL query template\n",
    "query_template = \"\"\"\n",
    "query fetch_poolDayDatas($poolAddress: String!, $cursorID: ID) {\n",
    "  poolDayDatas(\n",
    "    where: {pool: $poolAddress, id_gt: $cursorID}\n",
    "    first: 1000\n",
    "    orderBy: id\n",
    "    orderDirection: asc\n",
    "  ) {\n",
    "    id\n",
    "    high\n",
    "    low\n",
    "    tvlUSD\n",
    "    txCount\n",
    "    volumeUSD\n",
    "    date\n",
    "    open\n",
    "    tick    \n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Function to execute a GraphQL query\n",
    "def execute_graphql_query(subgraph_url, query, variables):\n",
    "    response = requests.post(subgraph_url, json={'query': query, 'variables': variables})\n",
    "    response.raise_for_status()  # This will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    json_response = response.json()\n",
    "    if 'errors' in json_response:\n",
    "        raise Exception(\"GraphQL Error: \" + json.dumps(json_response['errors']))\n",
    "    return json_response['data']['poolDayDatas']\n",
    "\n",
    "# Function to save data to a JSON file\n",
    "def save_to_file(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(data, outfile, indent=2)\n",
    "\n",
    "# Function to paginate through and fetch all pool day data\n",
    "def fetch_all_pool_day_data(subgraph_url, query, pool_address):\n",
    "    all_data = []\n",
    "    last_id = \"\"\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Fetching pool day data after ID {last_id}\")\n",
    "        batch = execute_graphql_query(subgraph_url, query, {'poolAddress': pool_address.lower(), 'cursorID': last_id})\n",
    "        if not batch:\n",
    "            break  # No more data to fetch\n",
    "        all_data.extend(batch)\n",
    "        last_id = batch[-1]['id']\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def timestamp_to_date(json_data):\n",
    "    for entry in json_data:\n",
    "        # Assuming 'date' is the key for the timestamp in the JSON object\n",
    "        timestamp = int(entry['date'])\n",
    "        # Convert Unix timestamp to datetime object\n",
    "        date_time = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "        # Format the datetime object as a string in the format 'YYYY-MM-DD'\n",
    "        entry['date'] = date_time.strftime('%Y-%m-%d')\n",
    "    return json_data\n",
    "\n",
    "def insert_missing_days(data):\n",
    "    if not data:\n",
    "        return data  # If the data list is empty, return it as is.\n",
    "\n",
    "    # Sort data by date just in case it's not already sorted\n",
    "    data.sort(key=lambda x: x['date'])\n",
    "\n",
    "    # Convert the first and last date in the data to datetime objects\n",
    "    first_date = datetime.datetime.strptime(data[0]['date'], '%Y-%m-%d')\n",
    "    last_date = datetime.datetime.strptime(data[-1]['date'], '%Y-%m-%d')\n",
    "\n",
    "    # Calculate the expected number of days based on the date range\n",
    "    expected_days = (last_date - first_date).days + 1\n",
    "    current_date = first_date\n",
    "\n",
    "    # Placeholder for the new dataset with no missing days\n",
    "    new_data = []\n",
    "\n",
    "    for i in range(expected_days):\n",
    "        # Convert current_date back to string to compare with data\n",
    "        current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # If the date matches, append the data and increment the index\n",
    "        if data and data[0]['date'] == current_date_str:\n",
    "            new_data.append(data.pop(0))\n",
    "        else:\n",
    "            print(f\"Inserting data at {current_date_str}\")\n",
    "            # Insert a new placeholder object for the missing date\n",
    "            new_data.append({\n",
    "                'id': None,\n",
    "                'high': None,\n",
    "                'low': None,\n",
    "                'tvlUSD': None,\n",
    "                'txCount': None,\n",
    "                'volumeUSD': None,\n",
    "                'date': current_date_str,\n",
    "                'open': None,\n",
    "                'tick': None,\n",
    "            })\n",
    "\n",
    "        # Increment the current_date by one day\n",
    "        current_date += datetime.timedelta(days=1)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def interpolate_json_data(json_data, keys_not_to_interpolate):\n",
    "    # Convert JSON to DataFrame\n",
    "    df = pd.DataFrame(json_data)\n",
    "    \n",
    "    # Save the columns that should not be interpolated\n",
    "    non_interpolated_data = df[keys_not_to_interpolate].copy()\n",
    "\n",
    "    # Replace 'null' string and 0 values with np.nan for the rest\n",
    "    for key in df.columns.difference(keys_not_to_interpolate):\n",
    "        df[key] = df[key].replace('null', np.nan).replace('0', np.nan).astype(float)\n",
    "\n",
    "    # Perform the interpolation on allowed keys\n",
    "    df_interpolated = df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "    # Fill first row NaNs if there are any after interpolation\n",
    "    df_interpolated.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    # Put back the non-interpolated data\n",
    "    for key in keys_not_to_interpolate:\n",
    "        df_interpolated[key] = non_interpolated_data[key]\n",
    "\n",
    "    # Convert DataFrame back to JSON\n",
    "    interpolated_json_data = df_interpolated.to_dict(orient='records')\n",
    "    return interpolated_json_data\n",
    "\n",
    "def reverse_prices(data):\n",
    "    for entry in data:\n",
    "        for field in ['high', 'low', 'open', 'close']:\n",
    "            if entry[field] is not None and entry[field] != 0:\n",
    "                entry[field] = 1 / entry[field]\n",
    "    return data\n",
    "\n",
    "def process_pool_day_data(subgraph_url, query, pool_address):\n",
    "    data = fetch_all_pool_day_data(subgraph_url, query, pool_address)\n",
    "\n",
    "    # Add the \"close\" attribute to each day\n",
    "    for i in range(len(data) - 1):\n",
    "        data[i]['close'] = data[i + 1]['open']\n",
    "    data[-1]['close'] = 0  # Handle the last data point\n",
    "\n",
    "    data = timestamp_to_date(data)\n",
    "    data = insert_missing_days(data)\n",
    "\n",
    "    keys_not_to_interpolate = ['id', 'date']\n",
    "    data = interpolate_json_data(data, keys_not_to_interpolate)\n",
    "\n",
    "    return data\n",
    "\n",
    "def fetch_and_process_all_pools(pool_list, subgraph_url, query, output_folder):\n",
    "    for pool in pool_list:\n",
    "        pool_address = pool['pool_address']\n",
    "        reversed_flag = pool['reversed']\n",
    "        output_file_path = os.path.join(output_folder, f\"poolDayData_{pool_address}.json\")\n",
    "\n",
    "        try:\n",
    "            data = process_pool_day_data(subgraph_url, query, pool_address)\n",
    "            if reversed_flag:\n",
    "                data = reverse_prices(data)\n",
    "            save_to_file(data, output_file_path)\n",
    "            print(f\"Data for pool {pool['pair']} processed and saved to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing pool {pool['pair']}:\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "def main():\n",
    "    pool_list = [\n",
    "        {\n",
    "            \"pair\": \"USDC-ETH\",\n",
    "            \"pool_address\": \"0x88e6A0c2dDD26FEEb64F039a2c41296FcB3f5640\",\n",
    "            \"reversed\": False\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"WBTC-USDC\",\n",
    "            \"pool_address\": \"0x99ac8cA7087fA4A2A1FB6357269965A2014ABc35\",\n",
    "            \"reversed\": True\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"UNI-USDC\",\n",
    "            \"pool_address\": \"0xD0fC8bA7E267f2bc56044A7715A489d851dC6D78\",\n",
    "            \"reversed\": True\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"LDO-USDC\",\n",
    "            \"pool_address\": \"0x78235D08B2aE7a3E00184329212a4d7AcD2F9985\",\n",
    "            \"reversed\": True\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"LINK-USDC\",\n",
    "            \"pool_address\": \"0xFAD57d2039C21811C8F2B5D5B65308aa99D31559\",\n",
    "            \"reversed\": True\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"MATIC-USDC\",\n",
    "            \"pool_address\": \"0x07A6E955bA4345BAe83Ac2A6fAa771fddd8A2011\",\n",
    "            \"reversed\": True\n",
    "        },\n",
    "        {\n",
    "            \"pair\": \"USDC-GRT\",\n",
    "            \"pool_address\": \"0xB06E7Ed37CFA8F0f2888355DD1913e45412798c5\",\n",
    "            \"reversed\": False\n",
    "        },\n",
    "    ]\n",
    "    output_folder = \"data\"  # Replace with your actual path\n",
    "    fetch_and_process_all_pools(pool_list, UNISWAP_V3_SUBGRAPH_URL, query_template, output_folder)\n",
    "\n",
    "# Call the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
